{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "class RandomRotation(object):\n",
    "    \"\"\"\n",
    "    https://github.com/pytorch/vision/tree/master/torchvision/transforms\n",
    "    Rotate the image by angle.\n",
    "    Args:\n",
    "        degrees (sequence or float or int): Range of degrees to select from.\n",
    "            If degrees is a number instead of sequence like (min, max), the range of degrees\n",
    "            will be (-degrees, +degrees).\n",
    "        resample ({PIL.Image.NEAREST, PIL.Image.BILINEAR, PIL.Image.BICUBIC}, optional):\n",
    "            An optional resampling filter.\n",
    "            See http://pillow.readthedocs.io/en/3.4.x/handbook/concepts.html#filters\n",
    "            If omitted, or if the image has mode \"1\" or \"P\", it is set to PIL.Image.NEAREST.\n",
    "        expand (bool, optional): Optional expansion flag.\n",
    "            If true, expands the output to make it large enough to hold the entire rotated image.\n",
    "            If false or omitted, make the output image the same size as the input image.\n",
    "            Note that the expand flag assumes rotation around the center and no translation.\n",
    "        center (2-tuple, optional): Optional center of rotation.\n",
    "            Origin is the upper left corner.\n",
    "            Default is the center of the image.\n",
    "    \"\"\"\n",
    "\n",
    "    def __init__(self, degrees, resample=False, expand=False, center=None):\n",
    "        if isinstance(degrees, numbers.Number):\n",
    "            if degrees < 0:\n",
    "                raise ValueError(\"If degrees is a single number, it must be positive.\")\n",
    "            self.degrees = (-degrees, degrees)\n",
    "        else:\n",
    "            if len(degrees) != 2:\n",
    "                raise ValueError(\"If degrees is a sequence, it must be of len 2.\")\n",
    "            self.degrees = degrees\n",
    "\n",
    "        self.resample = resample\n",
    "        self.expand = expand\n",
    "        self.center = center\n",
    "\n",
    "    @staticmethod\n",
    "    def get_params(degrees):\n",
    "        \"\"\"Get parameters for ``rotate`` for a random rotation.\n",
    "        Returns:\n",
    "            sequence: params to be passed to ``rotate`` for random rotation.\n",
    "        \"\"\"\n",
    "        angle = np.random.uniform(degrees[0], degrees[1])\n",
    "\n",
    "        return angle\n",
    "\n",
    "    def __call__(self, img):\n",
    "        \"\"\"\n",
    "            img (PIL Image): Image to be rotated.\n",
    "        Returns:\n",
    "            PIL Image: Rotated image.\n",
    "        \"\"\"\n",
    "        \n",
    "        def rotate(img, angle, resample=False, expand=False, center=None):\n",
    "            \"\"\"Rotate the image by angle and then (optionally) translate it by (n_columns, n_rows)\n",
    "            Args:\n",
    "            img (PIL Image): PIL Image to be rotated.\n",
    "            angle ({float, int}): In degrees degrees counter clockwise order.\n",
    "            resample ({PIL.Image.NEAREST, PIL.Image.BILINEAR, PIL.Image.BICUBIC}, optional):\n",
    "            An optional resampling filter.\n",
    "            See http://pillow.readthedocs.io/en/3.4.x/handbook/concepts.html#filters\n",
    "            If omitted, or if the image has mode \"1\" or \"P\", it is set to PIL.Image.NEAREST.\n",
    "            expand (bool, optional): Optional expansion flag.\n",
    "            If true, expands the output image to make it large enough to hold the entire rotated image.\n",
    "            If false or omitted, make the output image the same size as the input image.\n",
    "            Note that the expand flag assumes rotation around the center and no translation.\n",
    "            center (2-tuple, optional): Optional center of rotation.\n",
    "            Origin is the upper left corner.\n",
    "            Default is the center of the image.\n",
    "            \"\"\"\n",
    "                \n",
    "            return img.rotate(angle, resample, expand, center)\n",
    "\n",
    "        angle = self.get_params(self.degrees)\n",
    "\n",
    "        return rotate(img, angle, self.resample, self.expand, self.center)\n",
    "class RandomShift(object):\n",
    "    def __init__(self, shift):\n",
    "        self.shift = shift\n",
    "        \n",
    "    @staticmethod\n",
    "    def get_params(shift):\n",
    "        \"\"\"Get parameters for ``rotate`` for a random rotation.\n",
    "        Returns:\n",
    "            sequence: params to be passed to ``rotate`` for random rotation.\n",
    "        \"\"\"\n",
    "        hshift, vshift = np.random.uniform(-shift, shift, size=2)\n",
    "\n",
    "        return hshift, vshift \n",
    "    def __call__(self, img):\n",
    "        hshift, vshift = self.get_params(self.shift)\n",
    "        \n",
    "        return img.transform(img.size, Image.AFFINE, (1,0,hshift,0,1,vshift), resample=Image.BICUBIC, fill=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Downloading: \"http://data.lip6.fr/cadene/pretrainedmodels/se_resnext50_32x4d-a260b3a4.pth\" to C:\\Users\\Toshevikov/.torch\\models\\se_resnext50_32x4d-a260b3a4.pth\n"
     ]
    }
   ],
   "source": [
    "from PIL import Image,ImageFile\n",
    "import io\n",
    "import os\n",
    "import pandas as pd\n",
    "import csv\n",
    "import sys\n",
    "import cv2\n",
    "import numpy as np\n",
    "import time\n",
    "size=224\n",
    "import torch\n",
    "from torchvision.transforms import ColorJitter, ToTensor, Normalize,Compose,Resize,ToPILImage\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "from torchvision.datasets import ImageFolder\n",
    "from PIL import Image, ImageOps, ImageEnhance\n",
    "import numbers\n",
    "import Augmentor\n",
    "device = \"cpu\"\n",
    "p=Augmentor.Pipeline()\n",
    "p.zoom(probability=0.4, min_factor=1.1, max_factor=1.5)\n",
    "p.crop_centre(probability=0.4,percentage_area=0.2)\n",
    "p.random_brightness(probability=0.4,min_factor=0.7, max_factor=1.5)\n",
    "p.random_color(probability=0.4, min_factor=0.5, max_factor=2)\n",
    "p.gaussian_distortion(probability=0.2, grid_width=5, grid_height=5, magnitude=5,corner='bell',method='in')\n",
    "train_transform = Compose([\n",
    "    p.torch_transform(),\n",
    "#    ToPILImage(),\n",
    "    Resize((size,size)),\n",
    "    RandomRotation(degrees=12),\n",
    "    RandomShift(4),\n",
    "    ToTensor(),\n",
    "    Normalize(mean=[0.485, 0.456, 0.406],\n",
    "std=[0.229, 0.224, 0.225])\n",
    "])\n",
    "val_transform = Compose([\n",
    "    Resize((size,size)),\n",
    "    ToTensor(),\n",
    "    Normalize(mean=[0.485, 0.456, 0.406],\n",
    "std=[0.229, 0.224, 0.225])\n",
    "])\n",
    "batch_size = 64\n",
    "lr=3e-4\n",
    "train_dataset = ImageFolder('d:\\Python\\cv\\\\model_data', transform=train_transform, target_transform=None)\n",
    "val_dataset = ImageFolder('d:\\Python\\cv\\\\test_data', transform=val_transform, target_transform=None)\n",
    "\n",
    "train_loader = DataLoader(train_dataset, batch_size=batch_size, shuffle=True, \n",
    "                          drop_last=True)\n",
    "val_loader = DataLoader(val_dataset, batch_size=batch_size, shuffle=True,\n",
    "                        drop_last=False)\n",
    "\n",
    "import torch.nn as nn\n",
    "import torchvision.models as models\n",
    "import torch.nn.functional as F\n",
    "from senet import se_resnext50_32x4d\n",
    "class FineTune_Model(nn.Module):\n",
    "    def __init__(self,num_classes=2):\n",
    "        super().__init__()\n",
    "        self.basemodel=se_resnext50_32x4d(pretrained='imagenet', inchannels=3)\n",
    "        planes=2048\n",
    "        self.bottleneck_g = nn.BatchNorm1d(planes)\n",
    "        self.bottleneck_g.bias.requires_grad_(False)\n",
    "        self.dropout=nn.Dropout(0.2)\n",
    "        self.fc = nn.Linear(planes, num_classes)\n",
    "        nn.init.normal_(self.fc.weight, std=0.001)\n",
    "        nn.init.constant_(self.fc.bias, 0)\n",
    "    def forward(self,x):\n",
    "        x=self.basemodel(x)\n",
    "        x=F.avg_pool2d(x,x.size()[2:])\n",
    "        x=x.view(x.size(0),-1)\n",
    "        x=self.dropout(x)\n",
    "        x=self.bottleneck_g(x)\n",
    "        x=self.fc(x)\n",
    "        return x\n",
    "    def freeze(self):\n",
    "        for param in self.basemodel.parameters():\n",
    "            param.requires_grad = False\n",
    "        for param in self.basemodel.layer4.parameters():\n",
    "            param.requires_grad = True\n",
    "model=FineTune_Model()\n",
    "model.basemodel.requires_grad=False\n",
    "model.basemodel.layer4.requires_grad=True\n",
    "model.load_state_dict(torch.load('d:\\Python\\\\cv\\\\pytorch_model\\\\senet_model_train-2finish.pt'))\n",
    "model = model.to(device)\n",
    "criterion = nn.CrossEntropyLoss()\n",
    "optimizer = torch.optim.Adam(model.parameters())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/10.. Train loss: 0.349.. Train accuracy: 0.866.. Test loss: 0.311.. Test accuracy: 0.875\n",
      "Epoch 1/10.. Train loss: 0.348.. Train accuracy: 0.847.. Test loss: 0.350.. Test accuracy: 0.862\n",
      "Epoch 1/10.. Train loss: 0.349.. Train accuracy: 0.869.. Test loss: 0.353.. Test accuracy: 0.865\n",
      "Epoch 1/10.. Train loss: 0.382.. Train accuracy: 0.858.. Test loss: 0.442.. Test accuracy: 0.789\n",
      "Epoch 1/10.. Train loss: 0.320.. Train accuracy: 0.864.. Test loss: 0.524.. Test accuracy: 0.815\n",
      "Epoch 1/10.. Train loss: 0.363.. Train accuracy: 0.836.. Test loss: 0.352.. Test accuracy: 0.837\n",
      "Epoch 1/10.. Train loss: 0.341.. Train accuracy: 0.853.. Test loss: 0.323.. Test accuracy: 0.859\n",
      "Epoch 1/10.. Train loss: 0.254.. Train accuracy: 0.895.. Test loss: 0.340.. Test accuracy: 0.861\n",
      "Epoch 1/10.. Train loss: 0.402.. Train accuracy: 0.836.. Test loss: 0.468.. Test accuracy: 0.797\n",
      "Epoch 1/10.. Train loss: 0.339.. Train accuracy: 0.858.. Test loss: 0.432.. Test accuracy: 0.813\n",
      "Epoch 1/10.. Train loss: 0.357.. Train accuracy: 0.858.. Test loss: 0.309.. Test accuracy: 0.876\n",
      "Epoch 1/10.. Train loss: 0.310.. Train accuracy: 0.869.. Test loss: 0.294.. Test accuracy: 0.879\n",
      "Epoch 2/10.. Train loss: 0.308.. Train accuracy: 0.867.. Test loss: 0.296.. Test accuracy: 0.867\n",
      "Epoch 2/10.. Train loss: 0.312.. Train accuracy: 0.856.. Test loss: 0.343.. Test accuracy: 0.856\n",
      "Epoch 2/10.. Train loss: 0.311.. Train accuracy: 0.877.. Test loss: 0.414.. Test accuracy: 0.815\n",
      "Epoch 2/10.. Train loss: 0.313.. Train accuracy: 0.870.. Test loss: 0.367.. Test accuracy: 0.876\n",
      "Epoch 2/10.. Train loss: 0.366.. Train accuracy: 0.845.. Test loss: 0.324.. Test accuracy: 0.863\n",
      "Epoch 2/10.. Train loss: 0.328.. Train accuracy: 0.864.. Test loss: 0.366.. Test accuracy: 0.848\n",
      "Epoch 2/10.. Train loss: 0.281.. Train accuracy: 0.880.. Test loss: 0.300.. Test accuracy: 0.888\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-3-4836c7826f35>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m()\u001b[0m\n\u001b[0;32m     15\u001b[0m         \u001b[0mlogps\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mmodel\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mforward\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0minputs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     16\u001b[0m         \u001b[0mloss\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mcriterion\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mlogps\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mlabels\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 17\u001b[1;33m         \u001b[0mloss\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mbackward\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     18\u001b[0m         \u001b[0moptimizer\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mstep\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     19\u001b[0m         \u001b[0mrunning_loss\u001b[0m \u001b[1;33m+=\u001b[0m \u001b[0mloss\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mitem\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mD:\\Anaconda\\lib\\site-packages\\torch\\tensor.py\u001b[0m in \u001b[0;36mbackward\u001b[1;34m(self, gradient, retain_graph, create_graph)\u001b[0m\n\u001b[0;32m    100\u001b[0m                 \u001b[0mproducts\u001b[0m\u001b[1;33m.\u001b[0m \u001b[0mDefaults\u001b[0m \u001b[0mto\u001b[0m\u001b[0;31m \u001b[0m\u001b[0;31m`\u001b[0m\u001b[0;31m`\u001b[0m\u001b[1;32mFalse\u001b[0m\u001b[0;31m`\u001b[0m\u001b[0;31m`\u001b[0m\u001b[1;33m.\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    101\u001b[0m         \"\"\"\n\u001b[1;32m--> 102\u001b[1;33m         \u001b[0mtorch\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mautograd\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mbackward\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mgradient\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mretain_graph\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mcreate_graph\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    103\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    104\u001b[0m     \u001b[1;32mdef\u001b[0m \u001b[0mregister_hook\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mhook\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mD:\\Anaconda\\lib\\site-packages\\torch\\autograd\\__init__.py\u001b[0m in \u001b[0;36mbackward\u001b[1;34m(tensors, grad_tensors, retain_graph, create_graph, grad_variables)\u001b[0m\n\u001b[0;32m     88\u001b[0m     Variable._execution_engine.run_backward(\n\u001b[0;32m     89\u001b[0m         \u001b[0mtensors\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mgrad_tensors\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mretain_graph\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mcreate_graph\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 90\u001b[1;33m         allow_unreachable=True)  # allow_unreachable flag\n\u001b[0m\u001b[0;32m     91\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     92\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "epochs = 10\n",
    "steps = 0\n",
    "running_loss = 0\n",
    "print_every = 10\n",
    "train_losses, test_losses = [], []\n",
    "train_accuracy=0\n",
    "best_train=0\n",
    "best_val=0\n",
    "model.freeze()\n",
    "for epoch in range(epochs):\n",
    "    for inputs, labels in train_loader:\n",
    "        steps += 1\n",
    "        inputs, labels = inputs.to(device), labels.to(device)\n",
    "        optimizer.zero_grad()\n",
    "        logps = model.forward(inputs)\n",
    "        loss = criterion(logps, labels)\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "        running_loss += loss.item()\n",
    "        ps = torch.exp(logps)\n",
    "        top_p, top_class = ps.topk(1, dim=1)\n",
    "        equals = top_class == labels.view(*top_class.shape)\n",
    "        train_accuracy +=torch.mean(equals.type(torch.FloatTensor)).item()\n",
    "        \n",
    "        if steps % print_every == 0:\n",
    "            test_loss = 0\n",
    "            accuracy = 0\n",
    "            model.eval()\n",
    "            with torch.no_grad():\n",
    "                for inputs, labels in val_loader:\n",
    "                    inputs, labels = inputs.to(device),labels.to(device)\n",
    "                    logps = model.forward(inputs)\n",
    "                    batch_loss = criterion(logps, labels)\n",
    "                    test_loss += batch_loss.item()\n",
    "                    \n",
    "                    ps = torch.exp(logps)\n",
    "                    top_p, top_class = ps.topk(1, dim=1)\n",
    "                    equals = top_class == labels.view(*top_class.shape)\n",
    "                    accuracy +=torch.mean(equals.type(torch.FloatTensor)).item()\n",
    "            train_losses.append(running_loss/len(train_loader))\n",
    "            test_losses.append(test_loss/len(val_loader))                    \n",
    "            print(f\"Epoch {epoch+1}/{epochs}.. \"\n",
    "                  f\"Train loss: {running_loss/print_every:.3f}.. \"\n",
    "                  f\"Train accuracy: {train_accuracy/print_every:.3f}.. \"\n",
    "                  f\"Test loss: {test_loss/len(val_loader):.3f}.. \"\n",
    "                  f\"Test accuracy: {accuracy/len(val_loader):.3f}\")\n",
    "            if train_accuracy>=best_train and accuracy>=best_val:\n",
    "                best_train=train_accuracy\n",
    "                best_val=accuracy\n",
    "                torch.save(model.state_dict(),f'd:\\Python\\\\cv\\\\pytorch_model\\\\senet_model_train-{train_accuracy/print_every:.3f}_test-{accuracy/len(val_loader):.3f}.pt')\n",
    "            running_loss = 0\n",
    "            train_accuracy=0\n",
    "            model.train()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<filter object at 0x0000000007E319E8>\n"
     ]
    }
   ],
   "source": [
    "#torch.save(model.state_dict(),f'd:\\Python\\\\cv\\\\pytorch_model\\\\senet_model_train-3finish.pt')\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
