{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import base64\n",
    "from pdf2image import convert_from_path\n",
    "from PIL import Image,ImageFile\n",
    "import io\n",
    "import pytesseract\n",
    "import os\n",
    "import pandas as pd\n",
    "import csv\n",
    "import sys\n",
    "pytesseract.pytesseract.tesseract_cmd = r\"D:\\Tesseract-OCR\\tesseract.exe\"\n",
    "ImageFile.LOAD_TRUNCATED_IMAGES = True\n",
    "Image.MAX_IMAGE_PIXELS = None\n",
    "import cv2\n",
    "import numpy as np\n",
    "import time\n",
    "\n",
    "def text_extractor(img_pil,lng='eng',i=0):\n",
    "    if img_pil.size[0]>700 or img_pil.size[1]>700:\n",
    "        size=700\n",
    "        wpercent = (size / float(img_pil.size[0]))\n",
    "        hsize = int((float(img_pil.size[1]) * float(wpercent)))\n",
    "        img_pil = img_pil.resize((size, hsize), Image.ANTIALIAS)\n",
    "    img=np.array(img_pil)\n",
    "    try:\n",
    "        img = cv2.cvtColor(img, cv2.COLOR_BGR2GRAY)\n",
    "    except cv2.error:\n",
    "        pass\n",
    "    img = cv2.resize(img, None, fx=2, fy=2, interpolation=cv2.INTER_AREA)\n",
    "    # Apply dilation and erosion to remove some noise\n",
    "    kernel = np.ones((1, 1), np.uint8)\n",
    "    img = cv2.dilate(img, kernel, iterations=1)\n",
    "    img = cv2.erode(img, kernel, iterations=1)\n",
    "    result = pytesseract.image_to_string(img,lang=lng)\n",
    "    if len(result)==0 and i==0:\n",
    "        img_pil=img_pil.transpose(Image.ROTATE_270)\n",
    "        result=text_extractor(img_pil,lng,i=1)\n",
    "    if len(result)==0 and i==1:\n",
    "        img_pil=img_pil.transpose(Image.ROTATE_90)\n",
    "        result=text_extractor(img_pil,lng,i=2)\n",
    "    return result\n",
    "def pdf_converter(pdf):\n",
    "    pdf=base64.b64decode(pdf)\n",
    "    file = open('new.pdf', 'w+b')\n",
    "    file.write(pdf)\n",
    "    file.close()\n",
    "    pages = convert_from_path(r'new.pdf')\n",
    "    return pages[0]\n",
    "\n",
    "result=pd.DataFrame(columns=['Requestid','id','format','time','data_rus','data_eng'])\n",
    "path='d:\\Python\\cv\\Фото'\n",
    "\n",
    "csv.field_size_limit(100000000)\n",
    "for file in ['09_2018.csv','10_2018.csv','11_2018.csv','12_2018.csv','01_2019.csv']:\n",
    "    data=pd.read_csv(os.path.join(path,file), engine='python',sep=';',encoding = \"utf-8\",header=None,names=['id','requestid','Documenttype','Documentname','b64'])\n",
    "    data=data[~data['b64'].isnull()].reset_index(drop=True)\n",
    "    for i in range(len(data)):\n",
    "        start_time = time.time()\n",
    "        formt=data.Documentname[i].split('.')[-1]\n",
    "        try:\n",
    "            if formt=='pdf' or formt=='PDF':\n",
    "                img=pdf_converter(data.b64[i])\n",
    "            else:\n",
    "                img=Image.open(io.BytesIO(base64.b64decode(data.b64[i])))\n",
    "            txt_rus=text_extractor(img,lng='rus')\n",
    "            txt_eng=text_extractor(img)\n",
    "        except Exception:\n",
    "            continue\n",
    "        end_time=time.time()\n",
    "        result.loc[len(result)]=[data.requestid[i],data.id[i],formt,(end_time - start_time),txt_rus,txt_eng]\n",
    "result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Wall time: 1h 23min 22s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "import base64\n",
    "from pdf2image import convert_from_path\n",
    "from PIL import Image,ImageFile\n",
    "import io\n",
    "import os\n",
    "import pandas as pd\n",
    "import csv\n",
    "import sys\n",
    "ImageFile.LOAD_TRUNCATED_IMAGES = True\n",
    "Image.MAX_IMAGE_PIXELS = None\n",
    "import cv2\n",
    "import numpy as np\n",
    "import time\n",
    "from keras.applications.nasnet import NASNetLarge\n",
    "from keras.applications.nasnet import preprocess_input\n",
    "from keras.applications.nasnet import decode_predictions\n",
    "from keras.preprocessing import image\n",
    "model=NASNetLarge()\n",
    "def preprocess_image(img_data):\n",
    "    size=331\n",
    "#    wpercent = (size / float(img_pil.size[0]))\n",
    "#    hsize = int((float(img_pil.size[1]) * float(wpercent)))\n",
    "    img_pil = img_data.resize((size, size), Image.ANTIALIAS)\n",
    "    img_pil=image.img_to_array(img_pil)\n",
    "    img_pil=np.expand_dims(img_pil,axis=0)\n",
    "    img_pil=preprocess_input(img_pil)\n",
    "    return img_pil\n",
    "def class_prediction(img_pil,model=model):\n",
    "    features=model.predict(img)\n",
    "    result=decode_predictions(features)\n",
    "    result=[result[0][0][1],result[0][1][1],result[0][2][1]]\n",
    "    return result\n",
    "def pdf_converter(pdf):\n",
    "    pdf=base64.b64decode(pdf)\n",
    "    file = open('new.pdf', 'w+b')\n",
    "    file.write(pdf)\n",
    "    file.close()\n",
    "    pages = convert_from_path(r'new.pdf')\n",
    "    return pages[0]\n",
    "\n",
    "result=pd.DataFrame(columns=['Requestid','id','format','time','category_1','category_2','category_3'])\n",
    "path='d:\\Python\\cv\\Фото'\n",
    "csv.field_size_limit(100000000)\n",
    "for file in os.listdir(path):\n",
    "    data=pd.read_csv(os.path.join(path,file), engine='python',sep=';',encoding = \"utf-8\",header=None,names=['id','requestid','Documenttype','Documentname','b64'])\n",
    "    data=data[~data['b64'].isnull()].reset_index(drop=True)\n",
    "    for i in range(len(data)):\n",
    "        start_time = time.time()\n",
    "        formt=data.Documentname[i].split('.')[-1]\n",
    "        try:\n",
    "            if formt=='pdf' or formt=='PDF':\n",
    "                img=pdf_converter(data.b64[i])\n",
    "            else:\n",
    "                img=Image.open(io.BytesIO(base64.b64decode(data.b64[i]))).convert('RGB')\n",
    "            img=preprocess_image(img)\n",
    "            temp_data=class_prediction(img)\n",
    "        except Exception:\n",
    "            continue\n",
    "        end_time=time.time()\n",
    "        result.loc[len(result)]=[data.requestid[i],data.id[i],formt,(end_time - start_time),temp_data[0],temp_data[1],temp_data[2]]\n",
    "result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "metadata": {},
   "outputs": [],
   "source": [
    "result=pd.read_csv('photo_category.csv')\n",
    "result2=result.loc[(result['category_1']!='web_site')&(result['category_1']!='slide_rule')&\n",
    "          (result['category_2']!='web_site')&(result['category_2']!='slide_rule')&\n",
    "          (result['category_3']!='web_site')&(result['category_3']!='slide_rule')].sort_values(by=['Requestid'])\n",
    "alldata=alldata.loc[~alldata['requestid'].isin(result2['Requestid'].values)]\n",
    "alldata.to_csv('right_data.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import pandas as pd\n",
    "import csv\n",
    "import sys\n",
    "path='d:\\Python\\cv\\Фото'\n",
    "csv.field_size_limit(100000000)\n",
    "for num,file in enumerate(os.listdir(path)):\n",
    "    data=pd.read_csv(os.path.join(path,file), engine='python',sep=';',encoding = \"utf-8\",header=None,names=['id','requestid','Documenttype','Documentname','b64'])\n",
    "    data=data[~data['b64'].isnull()].reset_index(drop=True)\n",
    "    if num==0:\n",
    "        alldata=data\n",
    "    else:\n",
    "        alldata=alldata.append(data)\n",
    "result=pd.read_csv('photo_category.csv')\n",
    "result2=result.loc[(result['category_1']!='web_site')&(result['category_1']!='slide_rule')&\n",
    "          (result['category_2']!='web_site')&(result['category_2']!='slide_rule')&\n",
    "          (result['category_3']!='web_site')&(result['category_3']!='slide_rule')].sort_values(by=['Requestid'])\n",
    "alldata=alldata.loc[alldata['requestid'].isin(result['Requestid'].values)]\n",
    "alldata.to_csv('not_right_data.csv')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import pandas as pd\n",
    "import csv\n",
    "import sys\n",
    "from keras.applications.nasnet import preprocess_input\n",
    "import base64\n",
    "import io\n",
    "from pdf2image import convert_from_path\n",
    "from PIL import Image,ImageFile\n",
    "data=pd.read_csv('not_right_data.csv')\n",
    "data.requestid=data.requestid.astype(int)\n",
    "path='d:\\Python\\cv\\\\test_data'\n",
    "def preprocess_image(img_data):\n",
    "    size=331\n",
    "#    wpercent = (size / float(img_pil.size[0]))\n",
    "#    hsize = int((float(img_pil.size[1]) * float(wpercent)))\n",
    "    img_pil = img_data.resize((size, size), Image.ANTIALIAS)\n",
    "    return img_pil\n",
    "def pdf_converter(pdf):\n",
    "    pdf=base64.b64decode(pdf)\n",
    "    file = open('new.pdf', 'w+b')\n",
    "    file.write(pdf)\n",
    "    file.close()\n",
    "    pages = convert_from_path(r'new.pdf')\n",
    "    return pages[0]\n",
    "for i in range(len(data)):\n",
    "    formt=data.Documentname[i].split('.')[-1]\n",
    "    try:\n",
    "        if formt=='pdf' or formt=='PDF':\n",
    "            img=pdf_converter(data.b64[i])\n",
    "        else:\n",
    "            img=Image.open(io.BytesIO(base64.b64decode(data.b64[i]))).convert('RGB')\n",
    "        img=preprocess_image(img)\n",
    "    except Exception:\n",
    "        continue\n",
    "    img.save(os.path.join(path,str(data.requestid[i])+'_'+str(data.id[i])+'.jpg'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "D:\\Anaconda\\lib\\site-packages\\h5py\\__init__.py:36: FutureWarning: Conversion of the second argument of issubdtype from `float` to `np.floating` is deprecated. In future, it will be treated as `np.float64 == np.dtype(float).type`.\n",
      "  from ._conv import register_converters as _register_converters\n",
      "Using TensorFlow backend.\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import pandas as pd\n",
    "import csv\n",
    "import sys\n",
    "from keras.applications.nasnet import preprocess_input\n",
    "import base64\n",
    "import io\n",
    "from pdf2image import convert_from_path\n",
    "from PIL import Image,ImageFile\n",
    "csv.field_size_limit(100000000)\n",
    "data=pd.read_csv(r'D:\\Python\\cv\\\\CBU\\val_bad.csv', engine='python',sep=';',encoding = \"utf-8\",skiprows=1,header=None,names=['id','requestid','Documenttype','Documentname','b64'], error_bad_lines=False)\n",
    "#data.requestid=data.requestid.astype(int)\n",
    "path='d:\\Python\\cv\\\\dop_bad'\n",
    "def preprocess_image(img_data):\n",
    "    size=224\n",
    "#    wpercent = (size / float(img_pil.size[0]))\n",
    "#    hsize = int((float(img_pil.size[1]) * float(wpercent)))\n",
    "    img_pil = img_data.resize((size, size), Image.ANTIALIAS)\n",
    "    return img_pil\n",
    "def pdf_converter(pdf):\n",
    "    pdf=base64.b64decode(pdf)\n",
    "    file = open('new.pdf', 'w+b')\n",
    "    file.write(pdf)\n",
    "    file.close()\n",
    "    pages = convert_from_path(r'new.pdf')\n",
    "    return pages[0]\n",
    "for i in range(len(data)):\n",
    "    formt=data.Documentname[i].split('.')[-1]\n",
    "    try:\n",
    "        if formt=='pdf' or formt=='PDF':\n",
    "            img=pdf_converter(data.b64[i])\n",
    "        else:\n",
    "            img=Image.open(io.BytesIO(base64.b64decode(data.b64[i]))).convert('RGB')\n",
    "#        img=preprocess_image(img)\n",
    "    except Exception:\n",
    "        continue\n",
    "    img.save(os.path.join(path,str(data.requestid[i])+'_'+str(data.id[i])+'.jpg'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Wall time: 11min 2s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "import base64\n",
    "from pdf2image import convert_from_path\n",
    "from PIL import Image,ImageFile\n",
    "import io\n",
    "import os\n",
    "import pandas as pd\n",
    "import csv\n",
    "import sys\n",
    "ImageFile.LOAD_TRUNCATED_IMAGES = True\n",
    "Image.MAX_IMAGE_PIXELS = None\n",
    "import cv2\n",
    "import numpy as np\n",
    "import time\n",
    "\n",
    "result=pd.DataFrame(columns=['Requestid','id','format','size1','size2','size3'])\n",
    "path='d:\\Python\\cv\\Фото'\n",
    "csv.field_size_limit(100000000)\n",
    "for file in os.listdir(path):\n",
    "    data=pd.read_csv(os.path.join(path,file), engine='python',sep=';',encoding = \"utf-8\",header=None,names=['id','requestid','Documenttype','Documentname','b64'])\n",
    "    data=data[~data['b64'].isnull()].reset_index(drop=True)\n",
    "    for i in range(len(data)):\n",
    "        start_time = time.time()\n",
    "        formt=data.Documentname[i].split('.')[-1]\n",
    "        try:\n",
    "            if formt=='pdf' or formt=='PDF':\n",
    "                img=pdf_converter(data.b64[i])\n",
    "            else:\n",
    "                img=Image.open(io.BytesIO(base64.b64decode(data.b64[i]))).convert('RGB')\n",
    "            img=image.img_to_array(img)\n",
    "        except Exception:\n",
    "            continue\n",
    "        end_time=time.time()\n",
    "        result.loc[len(result)]=[data.requestid[i],data.id[i],formt,img.shape[0],img.shape[1],img.shape[2]]\n",
    "result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import torch,torchvision \n",
    "device='cpu'\n",
    "model=torch.load('d:\\Python\\\\cv\\\\pytorch_model\\\\second_version\\\\pytorch_model_train-1.000_test-0.984.pt')\n",
    "model.eval()\n",
    "path='D:\\Python\\cv\\TEST'\n",
    "test_transforms = torchvision.transforms.Compose([torchvision.transforms.Resize(224),\n",
    "                                      torchvision.transforms.ToTensor(),\n",
    "                                     ])\n",
    "def predict_image(image):\n",
    "    image=test_transforms(image).float()\n",
    "    image=image.unsqueeze_(0)\n",
    "    image=image.to(device)\n",
    "    output=model(image)\n",
    "    return output.data.cpu().numpy().argmax()\n",
    "from PIL import Image\n",
    "for file in os.listdir(path):\n",
    "    im=Image.open(os.path.join(path,file))\n",
    "    if predict_image(im)==0:\n",
    "        im.save(\"d:\\Python\\cv\\\\1\\\\bad\\\\\"+file)\n",
    "    else:\n",
    "        im.save(\"d:\\Python\\cv\\\\1\\\\good\\\\\"+file)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-1-df73cf204ad2>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m()\u001b[0m\n\u001b[0;32m      2\u001b[0m \u001b[0mim\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mconvert_from_path\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34mr'D:\\Python\\cv\\zapekin_spravka.pdf'\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0mstrict\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;32mTrue\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;36m0\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      3\u001b[0m \u001b[0mdevice\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;34m'cpu'\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 4\u001b[1;33m \u001b[1;32mimport\u001b[0m \u001b[0mtorch\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0mtorchvision\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m      5\u001b[0m \u001b[0mmodel\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mtorch\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mload\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34mr\"C:\\Users\\\\Toshevikov\\\\IPython\\\\Production\\\\pytorch_model_train-1.000_test-0.984.pt\"\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      6\u001b[0m \u001b[0mmodel\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0meval\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mD:\\Anaconda\\lib\\site-packages\\torch\\__init__.py\u001b[0m in \u001b[0;36m<module>\u001b[1;34m()\u001b[0m\n\u001b[0;32m    100\u001b[0m     \u001b[1;32mpass\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    101\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 102\u001b[1;33m \u001b[1;32mfrom\u001b[0m \u001b[0mtorch\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_C\u001b[0m \u001b[1;32mimport\u001b[0m \u001b[1;33m*\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    103\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    104\u001b[0m __all__ += [name for name in dir(_C)\n",
      "\u001b[1;32mD:\\Anaconda\\lib\\importlib\\_bootstrap.py\u001b[0m in \u001b[0;36m_find_and_load\u001b[1;34m(name, import_)\u001b[0m\n",
      "\u001b[1;32mD:\\Anaconda\\lib\\importlib\\_bootstrap.py\u001b[0m in \u001b[0;36m_find_and_load_unlocked\u001b[1;34m(name, import_)\u001b[0m\n",
      "\u001b[1;32mD:\\Anaconda\\lib\\importlib\\_bootstrap.py\u001b[0m in \u001b[0;36m_load_unlocked\u001b[1;34m(spec)\u001b[0m\n",
      "\u001b[1;32mD:\\Anaconda\\lib\\importlib\\_bootstrap.py\u001b[0m in \u001b[0;36mmodule_from_spec\u001b[1;34m(spec)\u001b[0m\n",
      "\u001b[1;32mD:\\Anaconda\\lib\\importlib\\_bootstrap_external.py\u001b[0m in \u001b[0;36mcreate_module\u001b[1;34m(self, spec)\u001b[0m\n",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "from pdf2image import convert_from_path\n",
    "im=convert_from_path(r'D:\\Python\\cv\\zapekin_spravka.pdf',strict=True)[0]\n",
    "device='cpu'\n",
    "import torch,torchvision\n",
    "model=torch.load(r\"C:\\Users\\\\Toshevikov\\\\IPython\\\\Production\\\\pytorch_model_train-1.000_test-0.984.pt\")\n",
    "model.eval()\n",
    "test_transforms = torchvision.transforms.Compose([torchvision.transforms.Resize(224),\n",
    "                                      torchvision.transforms.ToTensor(),\n",
    "                                     ])\n",
    "#функция прогноза модели\n",
    "def predict_image(image):\n",
    "    image=test_transforms(image).float()\n",
    "    image=image.unsqueeze_(0)\n",
    "    image=image.to(device)\n",
    "    output=model(image)\n",
    "    return output.data.cpu().numpy().argmax()\n",
    "#predict_image(im)\n",
    "import numpy as np\n",
    "#np.array(im)\n",
    "im"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
